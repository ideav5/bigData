//ssh login 91 server
//start shell
/was/spark/bin/spark-shell --master spark://10.144.134.91:7077   --name test --conf spark.cassandra.connection.host=10.144.134.95 spark.driver.host=10.144.134.66 "spark.executor.extraJavaOptions=-XX:MaxDirectMemorySize=128M -XX:-UseGCOverheadLimit -Xss10m" --total-executor-cores 12  --executor-memory 10G  --jars /home/hqdb/sparkTask/stream-1.0-SNAPSHOT/lib/jsr166e-1.1.0.jar,/home/hqdb/sparkTask/stream-1.0-SNAPSHOT/lib/stream-1.0-SNAPSHOT.jar,/home/hqdb/sparkTask/stream-1.0-SNAPSHOT/lib/spark-cassandra-connector-java_2.10-1.3.0-M1.jar,/home/hqdb/sparkTask/stream-1.0-SNAPSHOT/lib/spark-cassandra-connector_2.10-1.3.0-M1.jar,/home/hqdb/sparkTask/stream-1.0-SNAPSHOT/lib/cassandra-driver-core-2.1.6.jar,/home/hqdb/sparkTask/stream-1.0-SNAPSHOT/lib/guava-14.0.1.jar,/home/hqdb/sparkTask/stream-1.0-SNAPSHOT/lib/cassandra-thrift-2.1.3.jar,/home/hqdb/sparkTask/stream-1.0-SNAPSHOT/lib/joda-time-2.3.jar,/home/hqdb/sparkTask/stream-1.0-SNAPSHOT/lib/spark-csv_2.10-1.2.0.jar,/home/hqdb/sparkTask/stream-1.0-SNAPSHOT/lib/commons-csv-1.1.jar,/home/hqdb/sparkTask/stream-1.0-SNAPSHOT/lib/mysql-connector-java-5.1.34.jar,/home/hqdb/sparkTask/stream-1.0-SNAPSHOT/lib/stream-1.0-SNAPSHOT.jar


import com.moneylocker.data.analysis.util._
import org.apache.spark.rdd.JdbcRDD
import java.sql.ResultSet
import org.apache.log4j.{Level, Logger}
val logLevel = Level.ERROR
Logger.getLogger("org").setLevel(logLevel)


//cassandra sample
//create cassandraSQLContext
val cc = new org.apache.spark.sql.cassandra.CassandraSQLContext(sc);
//cassandra sql select return DataFrame
val df = cc.sql("select user_id , action_day_key , obtain_time from mlapp.ml_obtain_credit_log where action_day_key in(%s)".format(CassandraUtil.formatActionDayKeyParam(20150919)))
// for merge  table registerTempTable ==> cc.sql("select user_id from ml_obtain_credit_log");
df.registerTempTable("ML_OBTAIN_CREDIT_LOG")

//jdbc sample
// define structure
case class UserInfo(id: String, app_version: Int)
// load data
val userInfoRdd = new JdbcRDD[UserInfo](sc, () => JdbcConnectionFactory.getConnectionFactory(JdbcConnectionFactory.testUrl, "test", "test").getConnection,
      "select id , app_version from hq_user_info  WHERE state >= ? AND state <= ?", 1, 150, 2, (r: ResultSet) => {
        new UserInfo(r.getString(1), r.getInt(2))
})
// for merge table registerTempTable
cc.createDataFrame(userInfoRdd).registerTempTable("user_info")


// merge and select
val m =  cc.sql("select * from user_info u , ml_obtain_credit_log c where u.id = c.user_id")
println(m.first());


// save as csv
m.save("/tmp/ml/newcars", "com.databricks.spark.csv")




